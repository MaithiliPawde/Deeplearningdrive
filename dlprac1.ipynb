{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYvoIiMCmR5DLjOrvVOenb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaithiliPawde/Deeplearningdrive/blob/main/dlprac1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unitStep(v):\n",
        "   if v >= 0:\n",
        "    return 1\n",
        "   else:\n",
        "    return 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "   v = np.dot(w, x) + b\n",
        "   y = unitStep(v)\n",
        "   return y\n",
        "\n",
        "# AND Logic Function\n",
        "# w1 = 1, w2 = 1, b = -1.5\n",
        "def AND_logicFunction(x):\n",
        "   w = np.array([1, 1])\n",
        "   b = -1.5\n",
        "   return perceptronModel(x, w, b)\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
        "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4OOQzNURYUs",
        "outputId": "19d97f51-3654-44e5-bd95-4c72506e7d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(0, 1) = 0\n",
            "AND(1, 1) = 1\n",
            "AND(0, 0) = 0\n",
            "AND(1, 0) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oqSfFXD0qVIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# define Unit Step Function\n",
        "def unitStep(v):\n",
        "   if v >= 0:\n",
        "    return 1\n",
        "   else:\n",
        "    return 0\n",
        "\n",
        "# design Perceptron Model\n",
        "def perceptronModel(x, w, b):\n",
        "   v = np.dot(w, x) + b\n",
        "   y = unitStep(v)\n",
        "   return y\n",
        "\n",
        "# OR Logic Function\n",
        "\n",
        "# w1 = 1, w2 = 1, b = -1.5\n",
        "def AND_logicFunction(x):\n",
        "   w = np.array([1, 1])\n",
        "   b = -0.5\n",
        "   return perceptronModel(x, w, b)\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
        "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG-bVHyZRoLm",
        "outputId": "9c82b761-b3dd-4f5a-8271-cb6da3e3afcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(0, 1) = 1\n",
            "AND(1, 1) = 1\n",
            "AND(0, 0) = 0\n",
            "AND(1, 0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AND_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -1.5\n",
        "    return perceptronModel(x, w, b)\n",
        "\n",
        "# testing the Perceptron Model for AND gate\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"AND({}, {}) = {}\".format(0, 1, AND_logicFunction(test1)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 1, AND_logicFunction(test2)))\n",
        "print(\"AND({}, {}) = {}\".format(0, 0, AND_logicFunction(test3)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 0, AND_logicFunction(test4)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otw9AHmYRyrv",
        "outputId": "7c8e2eaa-37f6-4914-b109-52edfa9a601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(0, 1) = 0\n",
            "AND(1, 1) = 1\n",
            "AND(0, 0) = 0\n",
            "AND(1, 0) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OR Logic Function\n",
        "# w1 = 1, w2 = 1, b = -0.5\n",
        "def OR_logicFunction(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -0.5\n",
        "    return perceptronModel(x, w, b)\n",
        "\n",
        "# testing the Perceptron Model for OR gate\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"OR({}, {}) = {}\".format(0, 1, OR_logicFunction(test1)))\n",
        "print(\"OR({}, {}) = {}\".format(1, 1, OR_logicFunction(test2)))\n",
        "print(\"OR({}, {}) = {}\".format(0, 0, OR_logicFunction(test3)))\n",
        "print(\"OR({}, {}) = {}\".format(1, 0, OR_logicFunction(test4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj4xcCzCR3Pj",
        "outputId": "6feecc21-4475-4041-a178-5a639ffc4ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR(0, 1) = 1\n",
            "OR(1, 1) = 1\n",
            "OR(0, 0) = 0\n",
            "OR(1, 0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# define Unit Step Function\n",
        "def unitStep(v):\n",
        "\tif v >= 0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn 0\n",
        "\n",
        "# design Perceptron Model\n",
        "def perceptronModel(x, w, b):\n",
        "\tv = np.dot(w, x) + b\n",
        "\ty = unitStep(v)\n",
        "\treturn y\n",
        "\n",
        "# NOT Logic Function\n",
        "# w = -1, b = 0.5\n",
        "def NOT_logicFunction(x):\n",
        "\tw = -1\n",
        "\tb = 0.5\n",
        "\treturn perceptronModel(x, w, b)\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array(1)\n",
        "test2 = np.array(0)\n",
        "\n",
        "print(\"NOT({}) = {}\".format(1, NOT_logicFunction(test1)))\n",
        "print(\"NOT({}) = {}\".format(0, NOT_logicFunction(test2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpMIRxJRR8jV",
        "outputId": "dca684fd-753e-4aea-e3b2-85a891888b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT(1) = 0\n",
            "NOT(0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# define Unit Step Function\n",
        "def unitStep(v):\n",
        "\tif v >= 0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn 0\n",
        "\n",
        "# design Perceptron Model\n",
        "def perceptronModel(x, w, b):\n",
        "\tv = np.dot(w, x) + b\n",
        "\ty = unitStep(v)\n",
        "\treturn y\n",
        "\n",
        "# NOT Logic Function\n",
        "# wNOT = -1, bNOT = 0.5\n",
        "def NOT_logicFunction(x):\n",
        "\twNOT = -1\n",
        "\tbNOT = 0.5\n",
        "\treturn perceptronModel(x, wNOT, bNOT)\n",
        "\n",
        "# AND Logic Function\n",
        "# here w1 = wAND1 = 1,\n",
        "# w2 = wAND2 = 1, bAND = -1.5\n",
        "def AND_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbAND = -1.5\n",
        "\treturn perceptronModel(x, w, bAND)\n",
        "\n",
        "# OR Logic Function\n",
        "# w1 = 1, w2 = 1, bOR = -0.5\n",
        "def OR_logicFunction(x):\n",
        "\tw = np.array([1, 1])\n",
        "\tbOR = -0.5\n",
        "\treturn perceptronModel(x, w, bOR)\n",
        "\n",
        "# XOR Logic Function\n",
        "# with AND, OR and NOT\n",
        "# function calls in sequence\n",
        "def XOR_logicFunction(x):\n",
        "\ty1 = AND_logicFunction(x)\n",
        "\ty2 = OR_logicFunction(x)\n",
        "\ty3 = NOT_logicFunction(y1)\n",
        "\tfinal_x = np.array([y2, y3])\n",
        "\tfinalOutput = AND_logicFunction(final_x)\n",
        "\treturn finalOutput\n",
        "\n",
        "# testing the Perceptron Model\n",
        "test1 = np.array([0, 1])\n",
        "test2 = np.array([1, 1])\n",
        "test3 = np.array([0, 0])\n",
        "test4 = np.array([1, 0])\n",
        "\n",
        "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
        "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
        "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKrweBfOSIuE",
        "outputId": "c2981a39-7891-4052-a60c-cd3fc40689f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR(0, 1) = 1\n",
            "XOR(1, 1) = 0\n",
            "XOR(0, 0) = 0\n",
            "XOR(1, 0) = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9z4PMapSuCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA1yTE4PQOdZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def unitStep(v):\n",
        "  if v >  2:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def perceptronModel(x, w, b):\n",
        "  v = np.dot(w, x) + b\n",
        "  y = unitStep(v)\n",
        "  return y\n",
        "\n",
        "# AND Logic Function\n",
        "# w1 = 1, w2 = 1, w3 = 1, b = 1\n",
        "def F_logicFunction(x):\n",
        "  w = np.array([1, 1, 1])\n",
        "  b = 1\n",
        "  return perceptronModel(x, w, b)\n",
        "\n",
        "test1 = np.array([-1, -1, -1])\n",
        "test2 = np.array([-1, -1, 1])\n",
        "test3 = np.array([-1,  1, -1])\n",
        "test4 = np.array([-1,  1,  1])\n",
        "test5 = np.array([ 1, -1, -1])\n",
        "test6 = np.array([ 1, -1,  1])\n",
        "test7 = np.array([ 1,  1, -1])\n",
        "test8 = np.array([ 1,  1,  1])\n",
        "\n",
        "print(\"F({}, {}, {}) = {}\".format(-1, -1, -1, F_logicFunction(test1)))\n",
        "print(\"F({}, {}, {}) = {}\".format(-1, -1,  1, F_logicFunction(test2)))\n",
        "print(\"F({}, {}, {}) = {}\".format(-1,  1, -1, F_logicFunction(test3)))\n",
        "print(\"F({}, {}, {}) = {}\".format(-1,  1,  1, F_logicFunction(test4)))\n",
        "print(\"F({}, {}, {}) = {}\".format( 1, -1, -1, F_logicFunction(test5)))\n",
        "print(\"F({}, {}, {}) = {}\".format( 1, -1,  1, F_logicFunction(test6)))\n",
        "print(\"F({}, {}, {}) = {}\".format( 1,  1, -1, F_logicFunction(test7)))\n",
        "print(\"F({}, {}, {}) = {}\".format( 1,  1,  1, F_logicFunction(test8)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#define the data points\n",
        "data_points = {\n",
        "    'P0' : np.array([-1, -1, -1]),\n",
        "    'P1' : np.array([-1, -1, 1]),\n",
        "    'P2' : np.array([-1,  1, -1]),\n",
        "    'P3' : np.array([-1,  1, 1]),\n",
        "    'P4' : np.array([ 1, -1, -1]),\n",
        "    'P5' : np.array([ 1, -1,  1]),\n",
        "    'P6' : np.array([ 1,  1, -1]),\n",
        "    'P7' : np.array([ 1,  1,  1])\n",
        "\n",
        "}\n",
        "c1=['P7']\n",
        "c2=['P0','P1','P2','P3','P4','P5','P6']\n",
        "weights=np.zeros(len(data_points['P0']))\n",
        "bias=0\n",
        "print(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mZ1swX1SwFB",
        "outputId": "1c205a58-6257-4e23-ffe0-966fc1022e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def _init_(self, input_size, lr=1, epochs=100):\n",
        "        self.W = np.zeros(input_size+1)\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "\n",
        "    def activation_fn(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = np.insert(x, 0, 1)\n",
        "        z = self.W.T.dot(x)\n",
        "        a = self.activation_fn(z)\n",
        "        return a\n",
        "\n",
        "    def fit(self, X, d):\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(d.shape[0]):\n",
        "                y = self.predict(X[i])\n",
        "                e = d[i] - y\n",
        "                self.W = self.W + self.lr * e * np.insert(X[i], 0, 1)\n",
        "\n",
        "def main():\n",
        "    X = np.array([[-1, -1, -1],\n",
        "                  [-1, -1, 1],\n",
        "                  [-1, 1, -1],\n",
        "                  [-1, 1, 1],\n",
        "                  [1, -1, -1],\n",
        "                  [1, -1, 1],\n",
        "                  [1, 1, -1],\n",
        "                  [1, 1, 1]])\n",
        "    d = np.array([0, 0, 0, 0, 1, 1, 1, 1])  # Labels for linear separability\n",
        "\n",
        "    perceptron = Perceptron(input_size=3)\n",
        "    perceptron.fit(X, d)\n",
        "\n",
        "    print(\"Weights:\", perceptron.W)"
      ],
      "metadata": {
        "id": "GWb4457qS8yt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}